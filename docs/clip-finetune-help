Usage: main.py [OPTIONS]

  Text-driven diffusion model adaptation to the selected image manipulation.

Options:
  --config STR                    One of the available configs:
                                  celeba.yml, afhq.yml, church.yml, imagenet.yaml
                                  [required]

  --exp PATH                      Output directory for transformed images
                                  [required]

  --edit_attr STR                 Editing attribute, the full list can be found in './utils/text_dic.py'
                                  [required]

  --fast_noising_train BOOL       Whether to use stochastic or deterministic encoding for training data (1 - stoch, 0 - determ)
                                  We recommend using stochastic encoding when many training images are used.

  --fast_noising_test BOOL        Whether to use stochastic or deterministic encoding for test data (1 - stoch, 0 - determ)
                                  To process many test images, we recommend using stochastic encoding.

  --t0 INT                        Diffusion time step to encode an image (possible values: 0 - 999).
                                  Higher values are used for stronger transforms.
                                  - For stochastic encoding recommended values
                                    [200-350] - for shallow transforms (e.g, makeup)
                                    [350-500] - for strong transforms (e.g., zombie)
                                  - For deterministic encoding:
                                    [300-500] - for shallow transforms
                                    [450-700] - for strong transforms
                                  [required]

  --n_inv_step INT                If deterministic encoding is used, this option sets up a number
                                  of DDIM steps to encode an image. Recommended value - 40.

  --n_test_step INT               Number of DDIM steps to decode an encoded image
                                  Recommended values are from 1 to 6.
                                  Smaller values sometimes bring less artifacts.
                                  Higher values can produce stronger transforms.
                                  [required]

  --own_test STR                  Whether to use your own test images
                                  Possible values - [0, all, <your_image_name>]
                                  - 0 : use test images from one of the standard datasets
                                  - all : use all images from the './imgs_for_test' folder
                                  - <your_image_name> : use only one image from './imgs_for_test'
                                  with <your_image_name>
                                  [required]

  --own_training BOOL             Whether to use your own training set
                                  Possible values - [0, 1]
                                  - 0 : use training images from one of the standard datasets
                                  - 1 : use all images from the './imgs_for_train' folder for training
                                  [required]

  --single_image BOOL             Working setting: domain adaptation (0) or single image editing (1)
                                  - 1 : single image editing applies to your own image.
                                  You have to put the image in '/imgs_for_test'
                                  and fill --own_test <your_image_name>
                                  - 0 : domain adaptation setting can be run using own images
                                  or images from dataset.
                                  [required]

  --align_face BOOL               Whether to use the face alignment.
                                  We recommend using this option with your own images.
                                  [required]

  --n_train_img INT               Number of training images from a dataset
                                  If you're using images from dataset for training,
                                  then write the number of desired images (usually, 50).
                                  If you're using your own training, then this option can be skipped

  --n_test_img INT                Number of test images from a dataset
                                  If you're using your own test, then this option can be skipped

  --n_iter INT                    Number of fine-tuning iterations.
                                  For domain adaptation [from 1 to 10]
                                  For single image editing [from 3 to 20]
                                  [required]

  --lr_clip_finetune FLOAT        Learning rate.
                                  Recommended values are from 1e-6 to 2e-5.
                                  We find that higher lr is preferable for stronger transforms.

  --l1_loss_w FLOAT               Regularization coefficient.
                                  Recommended values are from 0 to 10.
                                  Higher values can reduce artifacts and text-irrelevant changes.
